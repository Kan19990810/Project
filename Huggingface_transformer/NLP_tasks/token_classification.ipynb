{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer . \n",
      "B-LOC   O  O              O  O   B-ORG    I-ORG O  O          O         B-PER  I-PER     O    O  O         O         O      O   O         O    O         O     O    B-LOC   O     O   O          O      O   O       O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][4][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][4][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    # ['[CLS]',\n",
    "#  'EU',\n",
    "#  'rejects',\n",
    "#  'German',\n",
    "#  'call',\n",
    "#  'to',\n",
    "#  'boycott',\n",
    "#  'British',\n",
    "#  'la',\n",
    "#  '##mb',\n",
    "#  '.',\n",
    "#  '[SEP]']\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    # [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        # [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        # [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a5af9eefaf41a4bb8a22066555df20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d218daece5cd46f88347d2f4376a3436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a092300ac6462997a243a960e45474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
      "[-100, 1, 2, -100]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.6 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.6 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/43.6 kB ? eta -:--:--\n",
      "     ------------------ -------------------- 20.5/43.6 kB 65.6 kB/s eta 0:00:01\n",
      "     ----------------------------------- -- 41.0/43.6 kB 140.3 kB/s eta 0:00:01\n",
      "     -------------------------------------- 43.6/43.6 kB 133.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\computer\\anaconda\\envs\\transformer\\lib\\site-packages (from seqeval) (1.24.4)\n",
      "Collecting scikit-learn>=0.21.3 (from seqeval)\n",
      "  Obtaining dependency information for scikit-learn>=0.21.3 from https://files.pythonhosted.org/packages/5f/08/c66e99f06fb73f727c870172f0962c103262ac68839cc05234709b7b45c2/scikit_learn-1.3.0-cp38-cp38-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.0-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/42.2 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/42.2 MB 151.3 kB/s eta 0:04:39\n",
      "     --------------------------------------- 0.0/42.2 MB 151.3 kB/s eta 0:04:39\n",
      "     --------------------------------------- 0.1/42.2 MB 187.3 kB/s eta 0:03:45\n",
      "     --------------------------------------- 0.1/42.2 MB 226.4 kB/s eta 0:03:06\n",
      "     --------------------------------------- 0.1/42.2 MB 240.2 kB/s eta 0:02:56\n",
      "     --------------------------------------- 0.1/42.2 MB 258.0 kB/s eta 0:02:44\n",
      "     --------------------------------------- 0.2/42.2 MB 262.1 kB/s eta 0:02:41\n",
      "     --------------------------------------- 0.2/42.2 MB 262.1 kB/s eta 0:02:41\n",
      "     --------------------------------------- 0.2/42.2 MB 265.0 kB/s eta 0:02:39\n",
      "     --------------------------------------- 0.3/42.2 MB 334.4 kB/s eta 0:02:06\n",
      "     --------------------------------------- 0.3/42.2 MB 360.9 kB/s eta 0:01:57\n",
      "     --------------------------------------- 0.3/42.2 MB 403.1 kB/s eta 0:01:44\n",
      "     --------------------------------------- 0.4/42.2 MB 444.7 kB/s eta 0:01:35\n",
      "     --------------------------------------- 0.5/42.2 MB 508.0 kB/s eta 0:01:23\n",
      "     --------------------------------------- 0.5/42.2 MB 548.0 kB/s eta 0:01:17\n",
      "      -------------------------------------- 0.6/42.2 MB 583.7 kB/s eta 0:01:12\n",
      "      -------------------------------------- 0.7/42.2 MB 625.9 kB/s eta 0:01:07\n",
      "      -------------------------------------- 0.7/42.2 MB 655.2 kB/s eta 0:01:04\n",
      "      -------------------------------------- 0.8/42.2 MB 691.0 kB/s eta 0:01:00\n",
      "      -------------------------------------- 0.9/42.2 MB 715.4 kB/s eta 0:00:58\n",
      "      -------------------------------------- 1.0/42.2 MB 761.9 kB/s eta 0:00:55\n",
      "      -------------------------------------- 1.0/42.2 MB 787.7 kB/s eta 0:00:53\n",
      "     - ------------------------------------- 1.1/42.2 MB 819.2 kB/s eta 0:00:51\n",
      "     - ------------------------------------- 1.2/42.2 MB 840.3 kB/s eta 0:00:49\n",
      "     - ------------------------------------- 1.3/42.2 MB 848.2 kB/s eta 0:00:49\n",
      "     - ------------------------------------- 1.3/42.2 MB 878.1 kB/s eta 0:00:47\n",
      "     - ------------------------------------- 1.4/42.2 MB 891.0 kB/s eta 0:00:46\n",
      "     - ------------------------------------- 1.5/42.2 MB 909.5 kB/s eta 0:00:45\n",
      "     - ------------------------------------- 1.5/42.2 MB 927.0 kB/s eta 0:00:44\n",
      "     - ------------------------------------- 1.6/42.2 MB 938.0 kB/s eta 0:00:44\n",
      "     - ------------------------------------- 1.7/42.2 MB 945.1 kB/s eta 0:00:43\n",
      "     - ------------------------------------- 1.7/42.2 MB 954.5 kB/s eta 0:00:43\n",
      "     - ------------------------------------- 1.8/42.2 MB 963.4 kB/s eta 0:00:42\n",
      "     - ------------------------------------- 1.9/42.2 MB 975.0 kB/s eta 0:00:42\n",
      "     - ------------------------------------- 2.0/42.2 MB 988.1 kB/s eta 0:00:41\n",
      "     - -------------------------------------- 2.0/42.2 MB 1.0 MB/s eta 0:00:41\n",
      "     -- ------------------------------------- 2.1/42.2 MB 1.0 MB/s eta 0:00:40\n",
      "     -- ------------------------------------- 2.2/42.2 MB 1.0 MB/s eta 0:00:39\n",
      "     -- ------------------------------------- 2.3/42.2 MB 1.0 MB/s eta 0:00:39\n",
      "     -- ------------------------------------- 2.4/42.2 MB 1.0 MB/s eta 0:00:38\n",
      "     -- ------------------------------------- 2.4/42.2 MB 1.1 MB/s eta 0:00:38\n",
      "     -- ------------------------------------- 2.5/42.2 MB 1.1 MB/s eta 0:00:38\n",
      "     -- ------------------------------------- 2.6/42.2 MB 1.1 MB/s eta 0:00:38\n",
      "     -- ------------------------------------- 2.7/42.2 MB 1.1 MB/s eta 0:00:37\n",
      "     -- ------------------------------------- 2.7/42.2 MB 1.1 MB/s eta 0:00:37\n",
      "     -- ------------------------------------- 2.8/42.2 MB 1.1 MB/s eta 0:00:37\n",
      "     -- ------------------------------------- 2.9/42.2 MB 1.1 MB/s eta 0:00:36\n",
      "     -- ------------------------------------- 3.0/42.2 MB 1.1 MB/s eta 0:00:36\n",
      "     -- ------------------------------------- 3.1/42.2 MB 1.1 MB/s eta 0:00:35\n",
      "     -- ------------------------------------- 3.2/42.2 MB 1.1 MB/s eta 0:00:35\n",
      "     --- ------------------------------------ 3.2/42.2 MB 1.1 MB/s eta 0:00:35\n",
      "     --- ------------------------------------ 3.3/42.2 MB 1.1 MB/s eta 0:00:35\n",
      "     --- ------------------------------------ 3.4/42.2 MB 1.1 MB/s eta 0:00:35\n",
      "     --- ------------------------------------ 3.5/42.2 MB 1.1 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.5/42.2 MB 1.1 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.6/42.2 MB 1.2 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.7/42.2 MB 1.2 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.7/42.2 MB 1.2 MB/s eta 0:00:34\n",
      "     --- ------------------------------------ 3.8/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 3.9/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 3.9/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 4.0/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 4.1/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     --- ------------------------------------ 4.1/42.2 MB 1.2 MB/s eta 0:00:33\n",
      "     ---- ----------------------------------- 4.2/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.3/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.4/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.5/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.5/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.6/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.6/42.2 MB 1.2 MB/s eta 0:00:32\n",
      "     ---- ----------------------------------- 4.7/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 4.8/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 4.8/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 4.9/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 5.0/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 5.0/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 5.1/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 5.2/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ---- ----------------------------------- 5.3/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ----- ---------------------------------- 5.3/42.2 MB 1.2 MB/s eta 0:00:31\n",
      "     ----- ---------------------------------- 5.4/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.5/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.5/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.6/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.6/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.7/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.8/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.9/42.2 MB 1.2 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 5.9/42.2 MB 1.3 MB/s eta 0:00:30\n",
      "     ----- ---------------------------------- 6.0/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ----- ---------------------------------- 6.1/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ----- ---------------------------------- 6.2/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ----- ---------------------------------- 6.2/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ----- ---------------------------------- 6.3/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.3/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.4/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.5/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.6/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.6/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.7/42.2 MB 1.3 MB/s eta 0:00:29\n",
      "     ------ --------------------------------- 6.8/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 6.8/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 6.9/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.0/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.1/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.1/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.2/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.2/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.3/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------ --------------------------------- 7.4/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 7.4/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 7.5/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 7.6/42.2 MB 1.3 MB/s eta 0:00:28\n",
      "     ------- -------------------------------- 7.6/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 7.7/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 7.8/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 7.8/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 7.9/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.0/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.1/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.1/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.2/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.3/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.3/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     ------- -------------------------------- 8.4/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     -------- ------------------------------- 8.5/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     -------- ------------------------------- 8.5/42.2 MB 1.3 MB/s eta 0:00:27\n",
      "     -------- ------------------------------- 8.6/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 8.7/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 8.7/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 8.8/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 8.9/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 8.9/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.0/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.1/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.1/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.2/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.3/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.4/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     -------- ------------------------------- 9.4/42.2 MB 1.3 MB/s eta 0:00:26\n",
      "     --------- ------------------------------ 9.5/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.6/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.7/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.7/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.8/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.9/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 9.9/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 10.0/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 10.1/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 10.1/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 10.2/42.2 MB 1.3 MB/s eta 0:00:25\n",
      "     --------- ------------------------------ 10.3/42.2 MB 1.4 MB/s eta 0:00:24\n",
      "     --------- ------------------------------ 10.4/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     --------- ------------------------------ 10.4/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     --------- ------------------------------ 10.5/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 10.6/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 10.6/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 10.7/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 10.8/42.2 MB 1.4 MB/s eta 0:00:23\n",
      "     ---------- ----------------------------- 10.8/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 10.9/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.0/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.1/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.1/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.2/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.3/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.4/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.4/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.5/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ---------- ----------------------------- 11.6/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 11.6/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 11.7/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 11.8/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 11.8/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 11.9/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 12.0/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 12.0/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 12.1/42.2 MB 1.4 MB/s eta 0:00:22\n",
      "     ----------- ---------------------------- 12.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.3/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.3/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.5/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.5/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.6/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ----------- ---------------------------- 12.6/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 12.7/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 12.8/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 12.9/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 12.9/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.0/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.1/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.1/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.3/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.3/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.4/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.5/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.6/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------ --------------------------- 13.7/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 13.7/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 13.8/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 13.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 13.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.0/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.0/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.0/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.1/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.1/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.1/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.2/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.3/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.4/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.5/42.2 MB 1.4 MB/s eta 0:00:21\n",
      "     ------------- -------------------------- 14.6/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.7/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     ------------- -------------------------- 14.7/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 14.8/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 14.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 14.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.0/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.0/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.1/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.2/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.2/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.3/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.3/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.5/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.6/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.6/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.6/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.6/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     -------------- ------------------------- 15.8/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 15.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 15.9/42.2 MB 1.4 MB/s eta 0:00:20\n",
      "     --------------- ------------------------ 16.0/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.0/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.1/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.2/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.2/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.3/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.4/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.5/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.5/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.6/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.7/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.7/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.8/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.8/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     --------------- ------------------------ 16.8/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 17.0/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 17.1/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 17.2/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 17.3/42.2 MB 1.4 MB/s eta 0:00:19\n",
      "     ---------------- ----------------------- 17.3/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.4/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.5/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.5/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.7/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.7/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.8/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.8/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.8/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ---------------- ----------------------- 17.9/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.1/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.1/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.2/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.2/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.2/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.3/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.4/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.4/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.5/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.6/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.6/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.7/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.8/42.2 MB 1.4 MB/s eta 0:00:18\n",
      "     ----------------- ---------------------- 18.9/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 19.0/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ----------------- ---------------------- 19.0/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.1/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.2/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.3/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.3/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.4/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.5/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.6/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.6/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.6/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.7/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.9/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 19.9/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------ --------------------- 20.0/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------ --------------------- 20.0/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------ --------------------- 20.0/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.1/42.2 MB 1.4 MB/s eta 0:00:17\n",
      "     ------------------- -------------------- 20.2/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.2/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.4/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.4/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.4/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.5/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.7/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.8/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.9/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.9/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 20.9/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     ------------------- -------------------- 21.1/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.1/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.2/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.2/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.4/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.4/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.4/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.4/42.2 MB 1.4 MB/s eta 0:00:16\n",
      "     -------------------- ------------------- 21.7/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.8/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.9/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 21.9/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 22.0/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 22.1/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     -------------------- ------------------- 22.1/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.2/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.3/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.3/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.4/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.5/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.6/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.6/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.7/42.2 MB 1.4 MB/s eta 0:00:15\n",
      "     --------------------- ------------------ 22.9/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 22.9/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.0/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.1/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.1/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     --------------------- ------------------ 23.2/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.3/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.3/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.4/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.5/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.6/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.7/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.7/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.8/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.9/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 23.9/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 24.0/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 24.1/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 24.1/42.2 MB 1.4 MB/s eta 0:00:14\n",
      "     ---------------------- ----------------- 24.2/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.3/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.4/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.5/42.2 MB 1.5 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.5/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.6/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.7/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.8/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.8/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.9/42.2 MB 1.4 MB/s eta 0:00:13\n",
      "     ----------------------- ---------------- 24.9/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.0/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.1/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.2/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.2/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ----------------------- ---------------- 25.3/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.4/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.5/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.5/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.6/42.2 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.7/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.7/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.8/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.8/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 25.9/42.2 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.0/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.1/42.2 MB 1.5 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.1/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.2/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.3/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------ --------------- 26.3/42.2 MB 1.4 MB/s eta 0:00:12\n",
      "     ------------------------- -------------- 26.4/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.5/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.6/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.6/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.7/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.8/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.8/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 26.9/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.0/42.2 MB 1.5 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.0/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.1/42.2 MB 1.5 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.2/42.2 MB 1.5 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.2/42.2 MB 1.5 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.3/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     ------------------------- -------------- 27.4/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 27.4/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 27.5/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 27.6/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 27.6/42.2 MB 1.4 MB/s eta 0:00:11\n",
      "     -------------------------- ------------- 27.7/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 27.8/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 27.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 27.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.0/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.1/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.1/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.2/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.3/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.4/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     -------------------------- ------------- 28.4/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.5/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.6/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.6/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.7/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.8/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.8/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.8/42.2 MB 1.5 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 28.9/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.0/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.1/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.1/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.3/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.3/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.4/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.5/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     --------------------------- ------------ 29.5/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 29.6/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.7/42.2 MB 1.4 MB/s eta 0:00:10\n",
      "     ---------------------------- ----------- 29.7/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.8/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.9/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.9/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.9/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 29.9/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.0/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.2/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.2/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.2/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.2/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.5/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ---------------------------- ----------- 30.5/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 30.6/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 30.7/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 30.8/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 30.8/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 30.9/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 31.0/42.2 MB 1.4 MB/s eta 0:00:09\n",
      "     ----------------------------- ---------- 31.0/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.1/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.2/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.3/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.4/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.4/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.5/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.6/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ----------------------------- ---------- 31.6/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 31.7/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 31.8/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 31.8/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 31.9/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.0/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.0/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.1/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.2/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.3/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.4/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.4/42.2 MB 1.4 MB/s eta 0:00:08\n",
      "     ------------------------------ --------- 32.5/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.6/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.6/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------ --------- 32.7/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 32.8/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 32.8/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 32.9/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.0/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.0/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.1/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.2/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.2/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.3/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.4/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.5/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.5/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.6/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.7/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     ------------------------------- -------- 33.7/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 33.8/42.2 MB 1.4 MB/s eta 0:00:07\n",
      "     -------------------------------- ------- 33.9/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 33.9/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.0/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.1/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.2/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.2/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.3/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.4/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.5/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.5/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.6/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.7/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     -------------------------------- ------- 34.8/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 34.8/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 34.9/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 35.0/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 35.1/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 35.1/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 35.2/42.2 MB 1.4 MB/s eta 0:00:06\n",
      "     --------------------------------- ------ 35.3/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.3/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.4/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.5/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.6/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.6/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.7/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.8/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     --------------------------------- ------ 35.9/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 35.9/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.0/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.1/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.1/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.2/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.3/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.4/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.4/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.5/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.6/42.2 MB 1.4 MB/s eta 0:00:05\n",
      "     ---------------------------------- ----- 36.7/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 36.7/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 36.8/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ---------------------------------- ----- 36.9/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.0/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.1/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.1/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.2/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.2/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.3/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.4/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.4/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.5/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.6/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.7/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.7/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.8/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.9/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ----------------------------------- ---- 37.9/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 38.0/42.2 MB 1.4 MB/s eta 0:00:04\n",
      "     ------------------------------------ --- 38.1/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.1/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.2/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.3/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.3/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.4/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.5/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.6/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.6/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.7/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.8/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.9/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 38.9/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ --- 39.0/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 39.1/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 39.2/42.2 MB 1.4 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 39.2/42.2 MB 1.5 MB/s eta 0:00:03\n",
      "     ------------------------------------- -- 39.3/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.4/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.4/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.5/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.6/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.7/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.7/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.8/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.9/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 39.9/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.0/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------- -- 40.0/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.1/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.2/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.3/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.4/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.4/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.5/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.6/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.6/42.2 MB 1.5 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.7/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.8/42.2 MB 1.4 MB/s eta 0:00:02\n",
      "     -------------------------------------- - 40.8/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 40.9/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.0/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 41.1/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.2/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.3/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.3/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.4/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.5/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.5/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.6/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.7/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.7/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.8/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.9/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.0/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.0/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.1/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.2 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.2/42.2 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn>=0.21.3->seqeval)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.0-cp38-cp38-win_amd64.whl (9.2 MB)\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.2 MB 297.7 kB/s eta 0:00:31\n",
      "   ---------------------------------------- 0.1/9.2 MB 297.7 kB/s eta 0:00:31\n",
      "   ---------------------------------------- 0.1/9.2 MB 297.7 kB/s eta 0:00:31\n",
      "    --------------------------------------- 0.1/9.2 MB 343.4 kB/s eta 0:00:27\n",
      "    --------------------------------------- 0.2/9.2 MB 456.4 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.2/9.2 MB 456.4 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.2/9.2 MB 444.3 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.3/9.2 MB 516.0 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.3/9.2 MB 582.0 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.4/9.2 MB 622.6 kB/s eta 0:00:15\n",
      "   - -------------------------------------- 0.5/9.2 MB 670.5 kB/s eta 0:00:14\n",
      "   -- ------------------------------------- 0.5/9.2 MB 726.3 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.6/9.2 MB 762.0 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.7/9.2 MB 806.1 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.7/9.2 MB 858.3 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.8/9.2 MB 892.9 kB/s eta 0:00:10\n",
      "   --- ------------------------------------ 0.9/9.2 MB 929.9 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 947.4 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.0/9.2 MB 953.7 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.1/9.2 MB 992.2 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 1.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.2/9.2 MB 1.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.3/9.2 MB 1.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.4/9.2 MB 1.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.4/9.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.5/9.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.6/9.2 MB 1.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.6/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.7/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.8/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.9/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.9/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.0/9.2 MB 1.1 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 2.1/9.2 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.1/9.2 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.2/9.2 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.3/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.3/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.4/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.5/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.6/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.6/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.7/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.8/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.8/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.9/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.0/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.1/9.2 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.1/9.2 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 3.2/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.2/9.2 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.3/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 3.4/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.5/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.6/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.6/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 3.7/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.8/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.9/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.0/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.0/9.2 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.1/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.2/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.2/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.3/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.4/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.5/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.5/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 4.6/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.7/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.7/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.8/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.9/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.0/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.0/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.1/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.1/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.2/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 5.3/9.2 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 5.4/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.4/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.5/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.6/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.6/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.7/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.8/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.9/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.9/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.0/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.0/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.1/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.2/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.2/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.3/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.4/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.4/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.5/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.6/9.2 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.7/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.9/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.0/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.0/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.1/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.2/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.3/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 7.4/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.4/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.5/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.6/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.6/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.7/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 7.8/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 7.9/9.2 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 8.0/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.0/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.1/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.4/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.5/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.7/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.8/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.2 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.0/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.2 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.2/9.2 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/302.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/302.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/302.2 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 61.4/302.2 kB 297.7 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/302.2 kB 357.2 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/302.2 kB 357.2 kB/s eta 0:00:01\n",
      "   --------- ----------------------------- 71.7/302.2 kB 357.2 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 143.4/302.2 kB 387.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/302.2 kB 491.5 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 194.6/302.2 kB 491.5 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 256.0/302.2 kB 491.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- 302.2/302.2 kB 548.8 kB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16189 sha256=e679df6adc46136dd020787bd57b968326a56a879f43e8b0bbc17e4b1c4156b8\n",
      "  Stored in directory: c:\\users\\kan\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built seqeval\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, seqeval\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0 scipy-1.10.1 seqeval-1.2.2 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95eead00c6ad4e14b7c1035d8432c44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 0.6666666666666666,\n",
       " 'overall_f1': 0.8,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\"\n",
    "metric.compute(predictions=[predictions], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at C:\\Users\\Kan\\.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model_checkpoint = r\"C:\\Users\\Kan\\.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d17ab76407848c597bb8130054feaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\File\\Practice\\Huggingface_transformer\\NLP_tasks\\token_classification.ipynb  28\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     train_dataset\u001b[39m=\u001b[39;49mtokenized_datasets[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     eval_dataset\u001b[39m=\u001b[39;49mtokenized_datasets[\u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data_collator\u001b[39m=\u001b[39;49mdata_collator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39;49mcompute_metrics,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\transformers\\trainer.py:506\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[39m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    503\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplace_model_on_device\n\u001b[0;32m    504\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mquantization_method\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m QuantizationMethod\u001b[39m.\u001b[39mBITS_AND_BYTES\n\u001b[0;32m    505\u001b[0m ):\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_move_model_to_device(model, args\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    508\u001b[0m \u001b[39m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\transformers\\trainer.py:730\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_move_model_to_device\u001b[39m(\u001b[39mself\u001b[39m, model, device):\n\u001b[1;32m--> 730\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m    731\u001b[0m     \u001b[39m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mparallel_mode \u001b[39m==\u001b[39m ParallelMode\u001b[39m.\u001b[39mTPU \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mtie_weights\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\transformers\\modeling_utils.py:2053\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2049\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2050\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2051\u001b[0m     )\n\u001b[0;32m   2052\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2053\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    897\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 899\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 593\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    594\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 897\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\File\\Practice\\Huggingface_transformer\\NLP_tasks\\token_classification.ipynb  29\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mpush_to_hub(commit_message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTraining complete\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\transformers\\trainer.py:3656\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[1;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[0;32m   3653\u001b[0m \u001b[39m# Wait for the current upload to be finished.\u001b[39;00m\n\u001b[0;32m   3654\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finish_current_push()\n\u001b[1;32m-> 3656\u001b[0m \u001b[39mreturn\u001b[39;00m upload_folder(\n\u001b[0;32m   3657\u001b[0m     repo_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhub_model_id,\n\u001b[0;32m   3658\u001b[0m     folder_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49moutput_dir,\n\u001b[0;32m   3659\u001b[0m     commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[0;32m   3660\u001b[0m     token\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mhub_token,\n\u001b[0;32m   3661\u001b[0m     run_as_future\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m blocking,\n\u001b[0;32m   3662\u001b[0m     ignore_patterns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39m_*\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m**/*\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   3663\u001b[0m )\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\hf_api.py:828\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    827\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\hf_api.py:3509\u001b[0m, in \u001b[0;36mHfApi.upload_folder\u001b[1;34m(self, repo_id, folder_path, path_in_repo, commit_message, commit_description, token, repo_type, revision, create_pr, parent_commit, allow_patterns, ignore_patterns, delete_patterns, multi_commits, multi_commits_verbose, run_as_future)\u001b[0m\n\u001b[0;32m   3497\u001b[0m     pr_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_commits_on_pr(\n\u001b[0;32m   3498\u001b[0m         repo_id\u001b[39m=\u001b[39mrepo_id,\n\u001b[0;32m   3499\u001b[0m         repo_type\u001b[39m=\u001b[39mrepo_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3506\u001b[0m         verbose\u001b[39m=\u001b[39mmulti_commits_verbose,\n\u001b[0;32m   3507\u001b[0m     )\n\u001b[0;32m   3508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3509\u001b[0m     commit_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_commit(\n\u001b[0;32m   3510\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m   3511\u001b[0m         repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[0;32m   3512\u001b[0m         operations\u001b[39m=\u001b[39;49mcommit_operations,\n\u001b[0;32m   3513\u001b[0m         commit_message\u001b[39m=\u001b[39;49mcommit_message,\n\u001b[0;32m   3514\u001b[0m         commit_description\u001b[39m=\u001b[39;49mcommit_description,\n\u001b[0;32m   3515\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   3516\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   3517\u001b[0m         create_pr\u001b[39m=\u001b[39;49mcreate_pr,\n\u001b[0;32m   3518\u001b[0m         parent_commit\u001b[39m=\u001b[39;49mparent_commit,\n\u001b[0;32m   3519\u001b[0m     )\n\u001b[0;32m   3520\u001b[0m     pr_url \u001b[39m=\u001b[39m commit_info\u001b[39m.\u001b[39mpr_url\n\u001b[0;32m   3522\u001b[0m \u001b[39mif\u001b[39;00m create_pr \u001b[39mand\u001b[39;00m pr_url \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\hf_api.py:828\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    827\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[1;32m--> 828\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\hf_api.py:2675\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[1;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[0;32m   2672\u001b[0m warn_on_overwriting_operations(operations)\n\u001b[0;32m   2674\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2675\u001b[0m     upload_modes \u001b[39m=\u001b[39m fetch_upload_modes(\n\u001b[0;32m   2676\u001b[0m         additions\u001b[39m=\u001b[39;49madditions,\n\u001b[0;32m   2677\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m   2678\u001b[0m         repo_id\u001b[39m=\u001b[39;49mrepo_id,\n\u001b[0;32m   2679\u001b[0m         token\u001b[39m=\u001b[39;49mtoken \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtoken,\n\u001b[0;32m   2680\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   2681\u001b[0m         endpoint\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint,\n\u001b[0;32m   2682\u001b[0m         create_pr\u001b[39m=\u001b[39;49mcreate_pr,\n\u001b[0;32m   2683\u001b[0m     )\n\u001b[0;32m   2684\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2685\u001b[0m     e\u001b[39m.\u001b[39mappend_to_message(_CREATE_COMMIT_NO_REPO_ERROR_MESSAGE)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\_commit_api.py:477\u001b[0m, in \u001b[0;36mfetch_upload_modes\u001b[1;34m(additions, repo_type, repo_id, token, revision, endpoint, create_pr)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_iterable(additions, \u001b[39m256\u001b[39m):\n\u001b[0;32m    465\u001b[0m     payload \u001b[39m=\u001b[39m {\n\u001b[0;32m    466\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfiles\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[0;32m    467\u001b[0m             {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m         ]\n\u001b[0;32m    475\u001b[0m     }\n\u001b[1;32m--> 477\u001b[0m     resp \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39;49mpost(\n\u001b[0;32m    478\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mendpoint\u001b[39m}\u001b[39;49;00m\u001b[39m/api/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrepo_type\u001b[39m}\u001b[39;49;00m\u001b[39ms/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrepo_id\u001b[39m}\u001b[39;49;00m\u001b[39m/preupload/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrevision\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    479\u001b[0m         json\u001b[39m=\u001b[39;49mpayload,\n\u001b[0;32m    480\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    481\u001b[0m         params\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mcreate_pr\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m\"\u001b[39;49m} \u001b[39mif\u001b[39;49;00m create_pr \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    482\u001b[0m     )\n\u001b[0;32m    483\u001b[0m     hf_raise_for_status(resp)\n\u001b[0;32m    484\u001b[0m     preupload_info \u001b[39m=\u001b[39m _validate_preupload_info(resp\u001b[39m.\u001b[39mjson())\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\requests\\sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[1;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    627\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \n\u001b[0;32m    629\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:63\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     64\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     65\u001b[0m     request_id \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\http\\client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1349\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\http\\client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    318\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\http\\client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 277\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    279\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at C:\\Users\\Kan\\.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\5532cc56f74641d4bb33641f5c76a55d11f846e0 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\File\\Practice\\Huggingface_transformer\\NLP_tasks\\token_classification.ipynb  33\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m accelerator \u001b[39m=\u001b[39m Accelerator()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model, optimizer, train_dataloader, eval_dataloader \u001b[39m=\u001b[39m accelerator\u001b[39m.\u001b[39;49mprepare(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model, optimizer, train_dataloader, eval_dataloader\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/Practice/Huggingface_transformer/NLP_tasks/token_classification.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\accelerate\\accelerator.py:1270\u001b[0m, in \u001b[0;36mAccelerator.prepare\u001b[1;34m(self, device_placement, *args)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_megatron_lm(\u001b[39m*\u001b[39margs)\n\u001b[0;32m   1269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1270\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\n\u001b[0;32m   1271\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_one(obj, first_pass\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_placement\u001b[39m=\u001b[39;49md) \u001b[39mfor\u001b[39;49;00m obj, d \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(args, device_placement)\n\u001b[0;32m   1272\u001b[0m     )\n\u001b[0;32m   1273\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_one(obj, device_placement\u001b[39m=\u001b[39md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, device_placement))\n\u001b[0;32m   1275\u001b[0m \u001b[39mif\u001b[39;00m tpu_should_fix_optimizer \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmixed_precision \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfp8\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\accelerate\\accelerator.py:1271\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1268\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_megatron_lm(\u001b[39m*\u001b[39margs)\n\u001b[0;32m   1269\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1270\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m-> 1271\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_one(obj, first_pass\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, device_placement\u001b[39m=\u001b[39;49md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(args, device_placement)\n\u001b[0;32m   1272\u001b[0m     )\n\u001b[0;32m   1273\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_one(obj, device_placement\u001b[39m=\u001b[39md) \u001b[39mfor\u001b[39;00m obj, d \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(result, device_placement))\n\u001b[0;32m   1275\u001b[0m \u001b[39mif\u001b[39;00m tpu_should_fix_optimizer \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmixed_precision \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfp8\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1276\u001b[0m     \u001b[39m# 2. grabbing new model parameters\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\accelerate\\accelerator.py:1083\u001b[0m, in \u001b[0;36mAccelerator._prepare_one\u001b[1;34m(self, obj, first_pass, device_placement)\u001b[0m\n\u001b[0;32m   1081\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_data_loader(obj, device_placement\u001b[39m=\u001b[39mdevice_placement)\n\u001b[0;32m   1082\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m-> 1083\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_model(obj, device_placement\u001b[39m=\u001b[39;49mdevice_placement)\n\u001b[0;32m   1084\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer):\n\u001b[0;32m   1085\u001b[0m     optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_optimizer(obj, device_placement\u001b[39m=\u001b[39mdevice_placement)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\accelerate\\accelerator.py:1364\u001b[0m, in \u001b[0;36mAccelerator.prepare_model\u001b[1;34m(self, model, device_placement, evaluation_mode)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1361\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt train a model that has been loaded in 8-bit precision with CPU or disk offload.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1362\u001b[0m         )\n\u001b[0;32m   1363\u001b[0m \u001b[39melif\u001b[39;00m device_placement \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverify_device_map(model):\n\u001b[1;32m-> 1364\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m   1366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnative_amp \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_type \u001b[39m!=\u001b[39m DistributedType\u001b[39m.\u001b[39mFSDP:\n\u001b[0;32m   1367\u001b[0m     model\u001b[39m.\u001b[39m_original_forward \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\transformers\\modeling_utils.py:2053\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2048\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2049\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`.to` is not supported for `4-bit` or `8-bit` bitsandbytes models. Please use the model as it is, since the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2050\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m model has already been set to the correct devices and casted to the correct `dtype`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2051\u001b[0m     )\n\u001b[0;32m   2052\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2053\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    897\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 899\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m    569\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 570\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    572\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    573\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    574\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    575\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    581\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 593\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    594\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32md:\\Computer\\Anaconda\\envs\\transformer\\lib\\site-packages\\torch\\nn\\modules\\module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    895\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    896\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 897\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 2.00 GiB total capacity; 1.14 GiB already allocated; 0 bytes free; 1.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
