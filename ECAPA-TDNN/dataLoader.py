"""
æ•°æ®è½½å…¥
"""

import glob
import numpy
import os
import random
import soundfile
import torch

from scipy import signal


class train_loader(object):
    def __init__(self, train_list, train_path, musan_path, rir_path, num_frames, **kwargs):
        self.train_path = train_path
        self.num_frames = num_frames

        # æ•°æ®å¢å¼ºé…ç½®
        self.noisetypes = {'noise', 'speech', 'music'}
        self.noisesnr = {'noise': [0, 15], 'speech': [13, 20], 'music': [5, 15]}
        self.numnoise = {'noise': [1, 1], 'speech': [3, 8], 'music': [1, 1]}
        self.noiselist = {}

        # è¯»å–musanä¸­çš„æ‰€æœ‰ç¯å¢ƒéŸ³é¢‘æ–‡ä»¶
        augment_files = glob.glob(os.path.join(musan_path, '*/*/*/*.wav'))

        # åˆ†åœºæ™¯å­˜æ”¾musanéŸ³é¢‘æ–‡ä»¶ï¼šspeechã€noiseã€music
        for file in augment_files:
            if file.split('/')[-4] not in self.noiselist:
                self.noiselist[file.split('/')[-4]] = []
            self.noiselist[file.split('/')[-4]].append(file)

        # è¯»å–rirä¸­æ‰€æœ‰ç¯å¢ƒéŸ³é¢‘æ–‡ä»¶
        self.rir_files = glob.glob(os.path.join(rir_path, '*/*/*.wav'))

        # æ ¹æ®listæ–‡ä»¶åŠ è½½æ•°æ®å’Œæ ‡ç­¾
        self.data_list = []
        self.data_label = []

        # ç»Ÿè®¡è¯´è¯è€…ï¼Œå¹¶æŒ‰IDæ’åº
        lines = open(train_list).read().splitlines()
        dictkeys = list(set([x.split()[0] for x in lines]))
        dictkeys.sort()
        # æ„é€ è¯´è¯è€…å­—å…¸ï¼Œ key:id, ii:ä¸‹æ ‡
        dictkeys = {key: ii for ii, key in enumerate(dictkeys)}

        # é‡æ–°éå†listæ–‡ä»¶ï¼Œæ„é€ è®­ç»ƒæ•°æ®é›†
        for index, line in enumerate(lines):
            speaker_label = dictkeys[line.split()[0]]
            file_name = os.path.join(train_path, line.split()[1])
            self.data_label.append(speaker_label)
            self.data_list.append(file_name)

    # æ ¹æ®data_list åŠ è½½éŸ³é¢‘æ•°æ®ï¼ŒéšæœºåŠ è½½ç¯å¢ƒéŸ³é¢‘
    def __getitem__(self, index):

        # è¯»å–wavæ–‡ä»¶ï¼Œ audioä¸ºéŸ³é¢‘ï¼Œ sr = 16000ä¸ºé‡‡æ ·ç‡
        audio, sr = soundfile.read(self.data_list[index])

        # æ ¹æ®è®¾ç½®å¸§ç‡è°ƒæ•´éŸ³é¢‘é•¿åº¦ å¸§ç§»16ms = 160ä¸ªæ•°æ®ç‚¹
        length = self.num_frames * 160 + 240
        # å¦‚æœéŸ³é¢‘é•¿åº¦çŸ­äºé¢„è®¾é•¿åº¦ï¼Œåˆ™å¡«å……
        if audio.shape[0] <= length:
            shortage = length - audio.shape[0]
            audio = numpy.pad(audio, (0, shortage), 'wrap')
        # è¿›è¡ŒéŸ³é¢‘è£å‰ªã€‚ å¦‚æœç»è¿‡å¡«å……ï¼Œä» 0 å¼€å§‹ï¼Œå¦åˆ™éšæœºä¸€ä¸ªå¼€å§‹ç‚¹
        start_frame = numpy.int64(random.random() * (audio.shape[0] - length))
        audio = audio[start_frame: start_frame + length]
        # åœ¨audio åŠ ä¸Š 0 ç»´, ä½œç”¨ï¼šè®© audio å˜æˆ 1 * length çš„çŸ©é˜µ
        audio = numpy.stack([audio], axis=0)

        # æ•°æ®å¢å¼ºï¼Œå¢åŠ å™ªéŸ³
        augtype = random.randint(0, 5)
        if augtype == 0:  # åŸéŸ³é¢‘
            audio = audio
        elif augtype == 1:  # éšæœºæ·»åŠ  rir éŸ³é¢‘
            audio = self.add_rev(audio)
        elif augtype == 2:  # æ¼”è®²
            audio = self.add_noise(audio, 'speech')
        elif augtype == 3:  # éŸ³ä¹
            audio = self.add_noise(audio, 'music')
        elif augtype == 4:  # å™ªéŸ³
            audio = self.add_noise(audio, 'noise')
        elif augtype == 5:  # æ··åˆå™ªéŸ³
            audio = self.add_noise(audio, 'speech')
            audio = self.add_noise(audio, 'music')
        # è¿”å›éŸ³é¢‘çš„ 0 ç»´ ä¸æ ‡ç­¾ï¼Œ ä½œç”¨ï¼šè¿”å›éŸ³é¢‘shape torch.Size([length])
        return torch.FloatTensor(audio[0]), self.data_label[index]

    def add_rev(self, audio):
        rir_file = random.choice(self.rir_files)
        rir, sr = soundfile.read(rir_file)
        # åœ¨ rir ä¸Šå¢åŠ  0 ç»´ ï¼Œ rir çš„ç»´æ•°ä¸º 2 ç»´ 1 * n
        rir = numpy.expand_dims(rir.astype(numpy.float), 0)
        # rir æ ‡å‡†å½’ä¸€åŒ–
        rir = rir / numpy.sqrt(numpy.sum(rir ** 2))
        # è¿”å› audio ä¸ rir å·ç§¯ç»“æœï¼Œæˆªå– ä¸ audio ç›¸åŒçš„é•¿åº¦, [:, :self.num_frames * 160 + 240] :è¿”å› 1 * length çŸ©é˜µ
        return signal.convolve(audio, rir, mode='full')[:, :self.num_frames * 160 + 240]

    def add_noise(self, audio, noisecat):
        # clean_db ä½œç”¨ï¼šéŸ³é¢‘åˆ†è´
        clean_db = 10 * numpy.log10(numpy.mean(audio ** 2) + 1e-4)
        # self.numnoise = {'noise': [1, 1], 'speech': [3, 8], 'music': [1, 1]}
        numnoise = self.numnoise[noisecat]
        # self.noiselist: musan noise æ–‡ä»¶è¡¨, éšé€‰é€‰å– numnoise ä¸ªéŸ³é¢‘æ–‡ä»¶
        noiselist = random.sample(self.noiselist[noisecat], random.randint(numnoise[0], numnoise[1]))
        noises = []
        for noise in noiselist:
            noiseaudio, sr = soundfile.read(noise)
            length = self.num_frames * 160 + 240
            if noiseaudio.shape[0] <= length:
                shortage = length - noiseaudio.shape[0]
                noiseaudio = numpy.pad(noiseaudio, (0, shortage), 'wrap')
            start_frame = numpy.int64(random.random() * (noiseaudio.shape[0] - length))
            noiseaudio = noiseaudio[start_frame: start_frame + length]
            noiseaudio = numpy.stack([noiseaudio], axis=0)

            # noise_db: å™ªéŸ³åˆ†è´
            noise_db = 10 * numpy.log10(numpy.mean(noiseaudio ** 2) + 1e-4)
            # self.noisesnr = {'noise': [0, 15], 'speech': [13, 20], 'music': [5, 15]}
            noisesnr = random.uniform(self.noisesnr[noisecat][0], self.noisesnr[noisecat][1])
            # æ ‡å‡†åŒ– noiseaudioï¼Œæ ¹æ®ä¿¡å™ªæ¯”è¿›è¡Œæ”¹å˜å™ªå£°åˆ†è´
            noises.append(numpy.sqrt(10 ** ((clean_db - noise_db - noisesnr) / 10)) * noiseaudio)
        # æ‰€æœ‰å™ªéŸ³éŸ³é¢‘åœ¨ç¬¬ 0 ç»´æ‹¼æ¥ï¼Œå†ç”± 0 ç»´è¿›è¡Œç´¯å’Œã€‚è¿™æ ·speech æœ‰å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œç´¯å’Œä¼šä¸ä¼šå¯¼è‡´å¹…å€¼è¿‡é«˜ï¼ŸğŸ‘ğŸ‘ğŸ‘ğŸ‘
        noise = numpy.sum(numpy.concatenate(noises, axis=0), axis=0, keepdims=True)
        return noise + audio
